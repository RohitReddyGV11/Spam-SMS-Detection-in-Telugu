{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22ff3fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9261    1.0000    0.9616       263\n",
      "           1     1.0000    0.9508    0.9748       427\n",
      "\n",
      "    accuracy                         0.9696       690\n",
      "   macro avg     0.9630    0.9754    0.9682       690\n",
      "weighted avg     0.9718    0.9696    0.9698       690\n",
      "\n",
      "\n",
      "=== Naive Bayes ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9490    0.7072    0.8105       263\n",
      "           1     0.8441    0.9766    0.9055       427\n",
      "\n",
      "    accuracy                         0.8739       690\n",
      "   macro avg     0.8966    0.8419    0.8580       690\n",
      "weighted avg     0.8841    0.8739    0.8693       690\n",
      "\n",
      "\n",
      "=== Random Forest ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9228    1.0000    0.9599       263\n",
      "           1     1.0000    0.9485    0.9736       427\n",
      "\n",
      "    accuracy                         0.9681       690\n",
      "   macro avg     0.9614    0.9742    0.9667       690\n",
      "weighted avg     0.9706    0.9681    0.9683       690\n",
      "\n",
      "\n",
      "Model Comparison:\n",
      "              Model  CV F1  Test Accuracy  Precision  Recall  F1 Score\n",
      "Logistic Regression 0.9473         0.9696     1.0000  0.9508    0.9748\n",
      "      Random Forest 0.9702         0.9681     1.0000  0.9485    0.9736\n",
      "        Naive Bayes 0.9111         0.8739     0.8441  0.9766    0.9055\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model      import LogisticRegression\n",
    "from sklearn.naive_bayes       import MultinomialNB\n",
    "from sklearn.ensemble          import RandomForestClassifier\n",
    "from sklearn.model_selection   import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics           import (accuracy_score, precision_score,\n",
    "                                       recall_score, f1_score, classification_report)\n",
    "\n",
    "# 1) LOAD & CLEAN\n",
    "df = pd.read_excel(r\"C:\\Users\\rohit\\OneDrive\\Documents\\Projects\\Capstone Project\\Training Dataset.xlsx\")\n",
    "\n",
    "# Drop stray header‐copy row & unnamed columns\n",
    "df = df[df[\"Category\"] != \"Category\"].copy()\n",
    "df.drop(columns=[c for c in df.columns if c.startswith(\"Unnamed\")], inplace=True)\n",
    "\n",
    "# Rename for clarity\n",
    "df.rename(columns={\"Category\": \"Label\", \"Messages\": \"Text\"}, inplace=True)\n",
    "\n",
    "# Drop any missing texts\n",
    "df.dropna(subset=[\"Text\"], inplace=True)\n",
    "\n",
    "# Encode labels: Ham=0, Spam=1\n",
    "df[\"Label\"] = df[\"Label\"].map({\"Ham\": 0, \"Spam\": 1}).astype(int)\n",
    "\n",
    "# 2) PREPROCESSING\n",
    "def clean_telugu(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\d+\", \"\", text)                     # remove digits\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)  # remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text)                    # collapse whitespace\n",
    "    return text.strip()\n",
    "\n",
    "df[\"Clean_Text\"] = df[\"Text\"].apply(clean_telugu)\n",
    "\n",
    "# 3) FEATURE EXTRACTION\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1,2),   # unigrams + bigrams\n",
    "    max_features=5000    # top 5k features by TF‑IDF score\n",
    ")\n",
    "X = vectorizer.fit_transform(df[\"Clean_Text\"])\n",
    "y = df[\"Label\"]\n",
    "\n",
    "# 4) TRAIN‑TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 5) MODEL SELECTION\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Naive Bayes\":         MultinomialNB(),\n",
    "    \"Random Forest\":       RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    # 5a) (Optional) 5‑fold CV on training data\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_f1 = cross_val_score(model, X_train, y_train, cv=cv,\n",
    "                             scoring=\"f1\", n_jobs=-1).mean()\n",
    "    \n",
    "    # 5b) Fit & predict on hold‑out\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 6) EVALUATION\n",
    "    acc  = accuracy_score(y_test,  y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec  = recall_score(y_test, y_pred)\n",
    "    f1   = f1_score(y_test,   y_pred)\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"CV F1\": round(cv_f1,4),\n",
    "        \"Test Accuracy\": round(acc,4),\n",
    "        \"Precision\": round(prec,4),\n",
    "        \"Recall\": round(rec,4),\n",
    "        \"F1 Score\": round(f1,4),\n",
    "    })\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# 7) SUMMARY\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"F1 Score\", ascending=False)\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb215450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# 1) LOAD & CLEAN\n",
    "df = pd.read_excel(r\"C:\\Users\\rohit\\OneDrive\\Documents\\Projects\\Capstone Project\\Training Dataset.xlsx\")\n",
    "\n",
    "# Drop stray header‐copy row & unnamed columns\n",
    "df = df[df[\"Category\"] != \"Category\"].copy()\n",
    "df.drop(columns=[c for c in df.columns if c.startswith(\"Unnamed\")], inplace=True)\n",
    "\n",
    "# Rename for clarity\n",
    "df.rename(columns={\"Category\": \"Label\", \"Messages\": \"Text\"}, inplace=True)\n",
    "\n",
    "# Drop any missing texts\n",
    "df.dropna(subset=[\"Text\"], inplace=True)\n",
    "\n",
    "# Encode labels: Ham=0, Spam=1\n",
    "df[\"Label\"] = df[\"Label\"].map({\"Ham\": 0, \"Spam\": 1}).astype(int)\n",
    "\n",
    "# 2) EXPLORATORY DATA ANALYSIS (EDA)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df, x='Label')\n",
    "plt.xticks([0, 1], ['Ham', 'Spam'])\n",
    "plt.title(\"Distribution of Spam vs. Ham\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Message length distribution\n",
    "df['Text_Length'] = df['Text'].apply(len)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df, x='Text_Length', hue='Label', bins=50, kde=True)\n",
    "plt.title(\"Message Length Distribution by Class\")\n",
    "plt.xlabel(\"Text Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Top 20 words in spam and ham\n",
    "spam_words = \" \".join(df[df['Label'] == 1]['Text']).split()\n",
    "ham_words = \" \".join(df[df['Label'] == 0]['Text']).split()\n",
    "\n",
    "spam_freq = Counter(spam_words)\n",
    "ham_freq = Counter(ham_words)\n",
    "\n",
    "spam_common = pd.DataFrame(spam_freq.most_common(20), columns=['Word', 'Frequency'])\n",
    "ham_common = pd.DataFrame(ham_freq.most_common(20), columns=['Word', 'Frequency'])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=spam_common, x='Frequency', y='Word', color='red')\n",
    "plt.title(\"Top 20 Words in Spam Messages\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Word\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=ham_common, x='Frequency', y='Word', color='green')\n",
    "plt.title(\"Top 20 Words in Ham Messages\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Word\")\n",
    "plt.show()\n",
    "\n",
    "# 3) TEXT PREPROCESSING\n",
    "def clean_telugu(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "df[\"Clean_Text\"] = df[\"Text\"].apply(clean_telugu)\n",
    "\n",
    "# 4) FEATURE EXTRACTION\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X = vectorizer.fit_transform(df[\"Clean_Text\"])\n",
    "y = df[\"Label\"]\n",
    "\n",
    "# 5) TRAIN‑TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 6) MODEL SELECTION\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Cross-validation F1 on training set\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_f1 = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # Train & predict\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"CV F1\": round(cv_f1, 4),\n",
    "        \"Test Accuracy\": round(acc, 4),\n",
    "        \"Precision\": round(prec, 4),\n",
    "        \"Recall\": round(rec, 4),\n",
    "        \"F1 Score\": round(f1, 4),\n",
    "    })\n",
    "\n",
    "    # Print report\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Ham\", \"Spam\"])\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix – {name}\")\n",
    "    plt.show()\n",
    "\n",
    "# 7) COMPARISON RESULTS\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"F1 Score\", ascending=False)\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# 8) MODEL COMPARISON VISUALIZATION\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=results_df, x=\"F1 Score\", y=\"Model\", palette=\"mako\")\n",
    "plt.title(\"Model Comparison by F1 Score\")\n",
    "plt.xlabel(\"F1 Score\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.xlim(0, 1)\n",
    "plt.grid(axis='x')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b7cf8-e58d-4eda-98cc-4486c0536454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new_telugu(text, model=models[\"Logistic Regression\"]):\n",
    "    cleaned = clean_telugu(text)\n",
    "    vectorized = vectorizer.transform([cleaned])\n",
    "    prediction = model.predict(vectorized)[0]\n",
    "    return \"Spam\" if prediction == 1 else \"Ham\"\n",
    "\n",
    "\n",
    "test_texts = [\n",
    "    \"మీరు ఒక లక్ష రూపాయలు గెలుచుకున్నారు! వివరాల కోసం ఈ లింక్‌ను క్లిక్ చేయండి.\",\n",
    "    \"ఈరోజు మీ విద్యార్థి కార్డు తీసుకురండి.\",\n",
    "    \"మీ బ్యాంకు ఖాతా సక్రియం చేయడానికి OTP పంపబడింది.\",\n",
    "    \"పాఠశాల గురువారం ఉదయం 9:00కి ప్రారంభమవుతుంది.\",\n",
    "    \"కాఫీకి వెళ్లుదాం నన్ను పిక్ చేయ్.\",\n",
    "    \"కొత్త స్నేహితులు మీ కాల్ కోసం ఎదురు చూస్తున్నారు.డయల్ 5567866110.\",\n",
    "    \"మీరు ఏమి చేస్తున్నారు.\",\n",
    "    \"నువ్వు రేపు ఇంటికి వస్తావా?\"\n",
    "]\n",
    "\n",
    "for txt in test_texts:\n",
    "    result = predict_new_telugu(txt)\n",
    "    print(f\" '{txt}' → {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
